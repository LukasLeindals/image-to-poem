{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model exploration\n",
    "\n",
    "In this notebook we explore how our different model components work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image-to-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "c:\\Users\\lukas\\miniconda3\\envs\\nlp_venv\\lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# create image_to_text model\n",
    "image_to_text = pipeline(\"image-to-text\", model=\"nlpconnect/vit-gpt2-image-captioning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\miniconda3\\envs\\nlp_venv\\lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description:  two pink flowers in a flower pot \n"
     ]
    }
   ],
   "source": [
    "text = image_to_text(DATA_PATH+\"poem_images/0.jpg\")[0][\"generated_text\"]\n",
    "print(\"Description: \", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online images\n",
    "\n",
    "Instead of a local path we can also pass an online image URL to the `image_to_text` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\miniconda3\\envs\\nlp_venv\\lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description:  [{'generated_text': 'a painting of a flower arrangement in a flowery sky '}]\n"
     ]
    }
   ],
   "source": [
    "text = image_to_text(\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2F3.bp.blogspot.com%2F-2pq1tT_bwRQ%2FUSMp_PHAjtI%2FAAAAAAAAThM%2FPX2H_FV13w4%2Fs1600%2FMaple%2BPoetic%2BWallpaper.jpg&f=1&nofb=1&ipt=efde060abd000da0e74c17c7171a6a56909b67445a355f7e04afe2f094360b36&ipo=images\")\n",
    "text = text[0][\"generated_text\"]\n",
    "print(\"Description: \", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple images\n",
    "\n",
    "We can give the model a list of images to caption. The model will then caption each image individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\miniconda3\\envs\\nlp_venv\\lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptions:  ['two pink flowers in a flower pot ', 'a row of boats sitting on a dock ']\n"
     ]
    }
   ],
   "source": [
    "texts = image_to_text([DATA_PATH+\"poem_images/0.jpg\", DATA_PATH+\"poem_images/3.jpg\"])\n",
    "descriptions = [text[0][\"generated_text\"] for text in texts]\n",
    "print(\"Descriptions: \", descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model - GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Poem 1----------\n",
      ", that I had someone, my thoughts, for each\n",
      "One, I've gone alone, I'm not alone at home in this garden?\n",
      "Where I'm like, I've gone to the door. I'm not alone.\n",
      "That was my face I've gone through the walls\n",
      " I will tell you, my dream and my tears;\n",
      " you're a child I am alone\n",
      ", I know you are alone I have a life, I have been\n",
      "; I'm going\n",
      "\n",
      "----------Poem 2----------\n",
      "\n",
      "\n",
      "Where I don't think I'm alone\n",
      "\n",
      "And I'm dying alone\n",
      "\n",
      "\n",
      "\n",
      "And I'm lonely\n",
      " I think of\n",
      "\n",
      "We've given him my life\n",
      "\n",
      "I am not who's too much\n",
      "And I am not alone\n",
      " I am here\n",
      " I love and you never leave me alone.\n",
      "But you're afraid\n",
      "â€”I'm not a little you alone\n",
      " I am not alone.\n",
      "My little mind\n",
      "The shadow of my home\n",
      " I don\n",
      "\n",
      "----------Poem 3----------\n",
      " with his own lies.I am with life, but you are aloneAnd you know me, alone alone,\n",
      "My voice to stop my self\n",
      "\n",
      "He was alone, to know not from your walls,\n",
      "The word of our choiceBut that I'm alone and myself will stop;\n",
      "With no thought I feel alone.\n",
      "\n",
      "When I am alone, with a fear that no man can be alone\n",
      "\n",
      "My voice alone and my own\n",
      "\n",
      "What life comes not so's\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from image_to_poem.language_model.gpt2 import GPT2Model\n",
    "\n",
    "model_dir = \"../models/language_models/model_20231123_190606/model/\"\n",
    "\n",
    "model = GPT2Model(model_dir)\n",
    "\n",
    "poems = model.generate(num_return_sequences=3)\n",
    "\n",
    "\n",
    "for i, poem in enumerate(poems):\n",
    "    print(\"-\"*10 + f\"Poem {i+1}\" + \"-\"*10)\n",
    "    print(poem)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\" and I am a man in my day\\n\\nMy own father died alone I'm alone\\n and I'm not.\\nWho was an angel?\\nAll my own\\nDon't know\\n I am\\nThe end all of my soul, no soul.\\nThat day I was brokenMy dreamAnd I'm not a thing\\n\\nMy family, I need a day; I'm alone, the shadow, the dark that is her\\nMy father, I cannot make me\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(prompt=\"this is a cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_params = 0\n",
    "\n",
    "params = [param for param in model.model.parameters()]\n",
    "\n",
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "`transformer` is not an nn.Parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lukas\\Git\\Studie\\CS4120-NLP\\image-to-poem\\notebooks\\model_exploration.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lukas/Git/Studie/CS4120-NLP/image-to-poem/notebooks/model_exploration.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mget_parameter(\u001b[39m\"\u001b[39;49m\u001b[39mtransformer\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\miniconda3\\envs\\nlp_venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:730\u001b[0m, in \u001b[0;36mModule.get_parameter\u001b[1;34m(self, target)\u001b[0m\n\u001b[0;32m    727\u001b[0m param: torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mParameter \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(mod, param_name)\n\u001b[0;32m    729\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(param, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mParameter):\n\u001b[1;32m--> 730\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m param_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m` is not an \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    731\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39mnn.Parameter\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    733\u001b[0m \u001b[39mreturn\u001b[39;00m param\n",
      "\u001b[1;31mAttributeError\u001b[0m: `transformer` is not an nn.Parameter"
     ]
    }
   ],
   "source": [
    "model.model.get_parameter(\"transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50259, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50259, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
