{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bruger\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from image_to_poem.poem_generator import PoemGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing image-to-text model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "c:\\Users\\Bruger\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing language model...\n",
      "Initializing BERT similarity model...\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "poem_generator = PoemGenerator(lm_model=\"../models/language_models/max_len-500\", \n",
    "                               sim_model=\"../models/similarity/model_20231129_221129\",\n",
    "                               n_candidates=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define image \n",
    "# img = \"../data/bird.png\"\n",
    "img = \"data:image/jpeg;base64,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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bruger\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a field with a bunch of flowers in the middle of it \n"
     ]
    }
   ],
   "source": [
    "desc = poem_generator.image_to_text(img)\n",
    "print(desc[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (12884 > 1024). Running this sequence through the model will result in indexing errors\n",
      "c:\\Users\\Bruger\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\transformers\\generation\\utils.py:1281: UserWarning: Input length of input_ids is 12884, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Bruger\\OneDrive - Danmarks Tekniske Universitet\\Skrivebord\\DTU-MatTek\\semester 9 - NU\\CS4120 - Natural Language Processing\\image-to-poem\\notebooks\\bird_example.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Bruger/OneDrive%20-%20Danmarks%20Tekniske%20Universitet/Skrivebord/DTU-MatTek/semester%209%20-%20NU/CS4120%20-%20Natural%20Language%20Processing/image-to-poem/notebooks/bird_example.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m poems \u001b[39m=\u001b[39m poem_generator\u001b[39m.\u001b[39;49mget_candidates(img)\n",
      "File \u001b[1;32mc:\\users\\bruger\\onedrive - danmarks tekniske universitet\\skrivebord\\dtu-mattek\\semester 9 - nu\\cs4120 - natural language processing\\image-to-poem\\image_to_poem\\poem_generator.py:51\u001b[0m, in \u001b[0;36mPoemGenerator.get_candidates\u001b[1;34m(self, description, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_candidates\u001b[39m(\u001b[39mself\u001b[39m, description: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     50\u001b[0m     \u001b[39m# use LM to generate N poems from the description \u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_model\u001b[39m.\u001b[39mgenerate(prompt \u001b[39m=\u001b[39m description, num_return_sequences\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mN, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\users\\bruger\\onedrive - danmarks tekniske universitet\\skrivebord\\dtu-mattek\\semester 9 - nu\\cs4120 - natural language processing\\image-to-poem\\image_to_poem\\language_model\\gpt2.py:116\u001b[0m, in \u001b[0;36mGPT2Model.generate\u001b[1;34m(self, prompt, max_length, num_return_sequences, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m encoded_prompt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer(prompt, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    115\u001b[0m \u001b[39m# sample the output\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m sample_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mgenerate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mencoded_prompt, pad_token_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mpad_token_id, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[39m# decode output\u001b[39;00m\n\u001b[0;32m    119\u001b[0m input_len \u001b[39m=\u001b[39m encoded_prompt[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39msize()[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m# length of input prompt - used to exclude input from output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\transformers\\generation\\utils.py:1719\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1711\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1712\u001b[0m         input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m   1713\u001b[0m         expand_size\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   1714\u001b[0m         is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1715\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1716\u001b[0m     )\n\u001b[0;32m   1718\u001b[0m     \u001b[39m# 13. run sample\u001b[39;00m\n\u001b[1;32m-> 1719\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample(\n\u001b[0;32m   1720\u001b[0m         input_ids,\n\u001b[0;32m   1721\u001b[0m         logits_processor\u001b[39m=\u001b[39mlogits_processor,\n\u001b[0;32m   1722\u001b[0m         logits_warper\u001b[39m=\u001b[39mlogits_warper,\n\u001b[0;32m   1723\u001b[0m         stopping_criteria\u001b[39m=\u001b[39mstopping_criteria,\n\u001b[0;32m   1724\u001b[0m         pad_token_id\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mpad_token_id,\n\u001b[0;32m   1725\u001b[0m         eos_token_id\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39meos_token_id,\n\u001b[0;32m   1726\u001b[0m         output_scores\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39moutput_scores,\n\u001b[0;32m   1727\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mreturn_dict_in_generate,\n\u001b[0;32m   1728\u001b[0m         synced_gpus\u001b[39m=\u001b[39msynced_gpus,\n\u001b[0;32m   1729\u001b[0m         streamer\u001b[39m=\u001b[39mstreamer,\n\u001b[0;32m   1730\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1731\u001b[0m     )\n\u001b[0;32m   1733\u001b[0m \u001b[39melif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mBEAM_SEARCH:\n\u001b[0;32m   1734\u001b[0m     \u001b[39m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m     beam_scorer \u001b[39m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   1736\u001b[0m         batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1737\u001b[0m         num_beams\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1742\u001b[0m         max_length\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mmax_length,\n\u001b[0;32m   1743\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\transformers\\generation\\utils.py:2801\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   2798\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2800\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 2801\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(\n\u001b[0;32m   2802\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_inputs,\n\u001b[0;32m   2803\u001b[0m     return_dict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   2804\u001b[0m     output_attentions\u001b[39m=\u001b[39moutput_attentions,\n\u001b[0;32m   2805\u001b[0m     output_hidden_states\u001b[39m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   2806\u001b[0m )\n\u001b[0;32m   2808\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2809\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1074\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m \u001b[39m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m \u001b[39m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m \u001b[39m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1071\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1074\u001b[0m transformer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[0;32m   1075\u001b[0m     input_ids,\n\u001b[0;32m   1076\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1077\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1078\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1079\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1080\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1081\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1082\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1083\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[0;32m   1084\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1085\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1086\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1087\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1088\u001b[0m )\n\u001b[0;32m   1089\u001b[0m hidden_states \u001b[39m=\u001b[39m transformer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1091\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:838\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[39mif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    837\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwte(input_ids)\n\u001b[1;32m--> 838\u001b[0m position_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwpe(position_ids)\n\u001b[0;32m    839\u001b[0m hidden_states \u001b[39m=\u001b[39m inputs_embeds \u001b[39m+\u001b[39m position_embeds\n\u001b[0;32m    841\u001b[0m \u001b[39mif\u001b[39;00m token_type_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[0;32m    163\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[0;32m    164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[1;32mc:\\Users\\Bruger\\miniconda3\\envs\\nlp_env\\lib\\site-packages\\torch\\nn\\functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2227\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2228\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2229\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2230\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2231\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2233\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "poems = poem_generator.get_candidates(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - Poem 1 - - - - -\n",
      "\n",
      "O, honey, how I can\n",
      "Find this bird, the one\n",
      "You got the tree that day\n",
      "Couldn’t find your heart,\n",
      "Now I’m searching\n",
      "For your eyes,\n",
      "For love you never got\n",
      "I know you’re not yet\n",
      "But I know I’ll see you\n",
      "And I’ll be there soon\n",
      "Until I die.\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "print(f\"- - - - - Poem {i} - - - - -\")\n",
    "print(poems[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
