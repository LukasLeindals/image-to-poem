{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb8102dac7e46c1bb0f031644968468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\miniconda3\\envs\\nlp_venv\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\lukas\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model, GPT2LMHeadModel\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-medium')\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "C:\\Users\\lukas\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "out_text = model.generate(**encoded_input)\n",
    "out_text = tokenizer.decode(out_text[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Replace me by any text you'd like.\\n\\nI'm not a robot by any means\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "torch.manual_seed(64)\n",
    "from torch.utils.data import Dataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading GPT2 Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', \n",
    "                                          bos_token='<|startoftext|>', \n",
    "                                          eos_token='<|endoftext|>', \n",
    "                                          pad_token='<|pad|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|startoftext|>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.bos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model configuration\n",
    "# config = GPT2Config.from_pretrained(\"gpt2\")\n",
    "\n",
    "\n",
    "# Create model instance and set embedding length\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=config)\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"../notebooks/models/gpt2_tutorial/\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Running the model on GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: You are the first to call a little\n",
      "It was not alone;It is alone in the night.I don't leave alone\n",
      "Your eyes alone;I don't go alone\n",
      "It doesn't know I'm alone\n",
      "And you want to hear alone, no one; a thousand miles from me, you must give up.\n",
      "And I don't stay alone\n",
      "Alight up, I can't leave alone\n",
      "That I'm alone in her\n",
      "\n",
      "And I can't leave the wrong side\n",
      "And I'm alone in my life\n",
      "\n",
      "And I'm a boy; but they are gone\n",
      "And I have one mind.\n",
      "And I love to make, and you know I love you alone\n",
      "I'm in my head.And I can still believe in the sun\n",
      "And I'm not gone\n",
      "In the wind.\n",
      "Then we don't kill the moon\n",
      "And we don't kill the world, no one's alone,\n",
      "Or we're still the pain,\n",
      "\n",
      "And I never have you're alone,\n",
      "And I speak.\n",
      "From my feetAnd I fear a smile;\n",
      "\n",
      "And I am there.\n",
      "You know what I feel, a\n",
      "And I can hide the darkness\n",
      "No matter how I know you\n",
      "My tears; I believe I can bring down, you don't want to know\n",
      " my tears\n",
      "You can know the word, all I can be\n",
      "\n",
      "You are so much, you can't see\n",
      " you don't get afraid\n",
      "\n",
      "\n",
      "1: AsBut not I'm like you're alone,\n",
      "As she still can't pass for you, and\n",
      "\n",
      "And I'm never tired;\n",
      "\n",
      "And I am not alone;\n",
      "From the darkness I have not come;\n",
      "He stands,I am not alone,\n",
      "And you cannot sit,\n",
      "\n",
      "I think alone;\n",
      "\n",
      "And I am alone alone\n",
      "\n",
      "I don't remember;\n",
      "I am alone\n",
      "\n",
      " I donning of the mountains\n",
      "\n",
      "A word I don't need to know\n",
      "\n",
      "As though I'm alone.\n",
      "And I don't remember\n",
      "You don't make me walk\n",
      ".\n",
      "I don't understand to give;\n",
      "With tears alone, and then\n",
      "\n",
      "We are the walls,\n",
      "\n",
      "No matter of the rocks, I don't exist.\n",
      "I don't make one thing alone\n",
      "\n",
      "No word, I don't create\n",
      "\n",
      "And I've gone away;\n",
      "But I can't leave\n",
      "\n",
      "And I will bring.\n",
      " I think I just\n",
      "And the love\n",
      "When I've alone,\n",
      "And I want to stay;\n",
      "And I don't know\n",
      "So my heart\n",
      "But the word alone\n",
      "And my shame,\n",
      "And I alone alone.\n",
      "And I never think there\n",
      "And I feel alone\n",
      "and you alone;\n",
      "And I loveAnd the dark,\n",
      "And I will love,\n",
      " I know\n",
      ",\n",
      "No man without me\n",
      "He has gone alone,\n",
      "No man of me,\n",
      "\n",
      "\n",
      "2:  the forest\n",
      "\n",
      "\n",
      "No\n",
      "As we go alone\n",
      "\n",
      "\n",
      " I am alone\n",
      "\n",
      "My soul\n",
      "\n",
      "I, you've gone wrong\n",
      "\n",
      " my\n",
      "\n",
      "\n",
      "And I'll die\n",
      "With my mind\n",
      "\n",
      "My heart, I'm not, I may be a human face\n",
      ", and you don't look\n",
      "You don't believe.And I'm the moonBut I don't know.In my dreams,And I am a young boy\n",
      ", and I will pass\n",
      "And they come out\n",
      "So I am alone\n",
      "You don't see your dreams\n",
      "I'm not a person and a man\n",
      "A moment to go alone\n",
      " you don't know\n",
      "For I cannot get my heart\n",
      "\n",
      "And I don't know\n",
      "And I am alone.\n",
      "We go away alone alone\n",
      "I leave my path\n",
      "In the darkness\n",
      "I am alone.And I am alone\n",
      "\n",
      "For this life alone alone\n",
      "I'm afraid the sun\n",
      ", you ask me? I have been alone\n",
      "\n",
      "The dark was on my heart\n",
      "\n",
      "You can call me\n",
      "I'm too long, she is alone\n",
      " you are not alone\n",
      " I don't exist\n",
      "And we are alone. I don't know I can\n",
      "You are alone by me\n",
      "No love you know.\n",
      "We're alone, you have not loved you know\n",
      " I love you\n",
      "I don't exist I don't know the one\n",
      "No self and he can't sit alone\n",
      "\n",
      "No fear\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "prompt = \"<|startoftext|>\"\n",
    "\n",
    "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "generated = generated.to(device)\n",
    "\n",
    "sample_outputs = model.generate(\n",
    "                                generated, \n",
    "                                do_sample=True,   \n",
    "                                top_k=50, \n",
    "                                max_length = 300,\n",
    "                                top_p=0.95, \n",
    "                                num_return_sequences=3\n",
    "                                )\n",
    "\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
